<html>
  
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="../../../style.css">
    <base target="_parent">
  </head>
  
  <body>
    <div class="content">
       <h1>Dynamic programming</h1>

      <div class="ck-content">
        <p style="margin-left:0px;">Dynamic programming is a method in computer science and mathematics for
          solving complex problems by decomposing them into smaller overlapping subproblems,
          often used in optimization scenarios. Its essence lies in solving each
          subproblem only once and storing its solution, typically in a table or
          memoization array, to avoid recomputation. The process involves three main
          steps:</p>
        <ol>
          <li style="margin-left:0px;"><strong>Characterizing the Optimal Solution's Structure</strong>: Identifying
            the subproblems and understanding how the optimal solution of the main
            problem relates to the optimal solutions of these subproblems.</li>
          <li
          style="margin-left:0px;"><strong>Defining the Optimal Solution Recursively</strong>: Formulating
            a recursive equation that relates the value of an optimal solution to the
            values of smaller subproblems.</li>
            <li style="margin-left:0px;"><strong>Computing the Optimal Solution</strong>: Starting from the smallest
              subproblems, solutions are built in a bottom-up approach to eventually
              solve the original problem.</li>
        </ol>
        <p style="margin-left:0px;">Dynamic programming excels in efficiency and makes feasible the solving
          of problems that are otherwise computationally daunting. Its applications
          span across computer science, operations research, economics, bioinformatics,
          and more.</p>
        <h2>Principal of Optimality</h2>
        <p>The Principle of Optimality, or Bellman's Principle, is a key concept
          in dynamic programming. It states that in an optimal solution to a problem,
          all its subpaths are also optimal solutions to their respective subproblems.
          This principle is essential because it allows for a problem to be divided
          into smaller, independently solvable subproblems. Solutions to these subproblems
          can be combined to solve the original problem optimally. It also promotes
          efficiency by using a table or memoization array to store solutions to
          subproblems, preventing redundant computations. This principle leverages
          the optimal substructure property to solve complex problems efficiently.</p>
        <p>&nbsp;</p>
        <p>Example: Fibonaci</p><pre><code class="language-text-plain">table = {
	0: 0,
	1: 1,
	2: 1
}

def fibtable(n):
    if n in table:
        return table[n]
    table[n] = fibtable(n-1) + fibtable(n-2)
    return table[n]</code></pre>
      </div>
    </div>
  </body>

</html>