<html>
  
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="../../../../../style.css">
    <base target="_parent">
  </head>
  
  <body>
    <div class="content">
       <h1>Gradient Descent</h1>

      <div class="ck-content">
        <p style="margin-left:0px;">Gradient descent is an iterative optimization algorithm used in machine
          learning to minimize a model's cost function. It adjusts the model's parameters
          towards the steepest descent of the cost function. The algorithm updates
          parameters iteratively, moving opposite to the cost function's gradient,
          guided by a learning rate that determines the step size.</p>
        <p style="margin-left:0px;">A suitable learning rate is crucial; too small leads to slow convergence,
          too large risks overshooting the minimum. The process involves calculating
          gradients and updating parameters until certain criteria, like a maximum
          number of iterations or desired convergence level, are met.</p>
        <p style="margin-left:0px;">Gradient descent is key in various algorithms, including linear and logistic
          regression, and neural networks, aiding in optimal parameter determination.</p>
        <p
        style="margin-left:0px;"><span class="math-tex">\(x_{new}=x_{old}−η⋅∇f(x_{old})\)</span>
          </p>
      </div>
    </div>
  </body>

</html>